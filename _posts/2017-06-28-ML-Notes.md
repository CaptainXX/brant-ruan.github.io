---
title: Coursera | Machine Learning Notes
category: CS
---

## Coursera | Machine Learning Notes

### Preface

**All the resources here belong to Andrew Ng and relative staffs.**

**I download them from [Coursera](https://www.coursera.org/).**

**Sincerely, thanks for your teaching and your sharing of knowledge and technique.**

**Thank you, Andrew Ng.**

### Slides

- [Lecture1.pdf]({{ site.url }}/resources/pdf/Lecture1.pdf)
- [Lecture2.pdf]({{ site.url }}/resources/pdf/Lecture2.pdf)
- [Lecture3.pdf]({{ site.url }}/resources/pdf/Lecture3.pdf)
- [Lecture4.pdf]({{ site.url }}/resources/pdf/Lecture4.pdf)
- [Lecture5.pdf]({{ site.url }}/resources/pdf/Lecture5.pdf)
- [Lecture6.pdf]({{ site.url }}/resources/pdf/Lecture6.pdf)
- [Lecture7.pdf]({{ site.url }}/resources/pdf/Lecture7.pdf)
- [Lecture8.pdf]({{ site.url }}/resources/pdf/Lecture8.pdf)
- [Lecture9.pdf]({{ site.url }}/resources/pdf/Lecture9.pdf)

### Videos

**Week 1**

- [Welcome to Machine Learning]({{ site.url }}/resources/videos/ml-week1-1-welcome-to-machine-learning.mp4)

**Week 2**

**Week 3**

**Week 4**

**Week 5**

**Week 6**

**Week 7**

**Week 8**

**Week 9**

**Week 10**

**Week 11**

### Programming Tasks

- [machine-learning-ex1.zip]({{ site.url }}/resources/code/machine-learning-ex1.zip)
- [machine-learning-ex2.zip]({{ site.url }}/resources/code/machine-learning-ex2.zip)
- [machine-learning-ex3.zip]({{ site.url }}/resources/code/machine-learning-ex3.zip)
- [machine-learning-ex4.zip]({{ site.url }}/resources/code/machine-learning-ex4.zip)

### My Notes

#### Week 1

#### Week 2

#### Week 3

#### Week 4

#### Week 5

##### Basic Knowledge

I Found that the Resources on the web site are very useful.

##### BPNN Implement Notes

When implementing BPNN, you should be clear about the exact definition of `z` and `a`, that is:

{% highlight matlab %}
delta2 = zeros(hidden_layer_size, 1);
delta3 = zeros(num_labels, 1);
Delta2 = zeros(hidden_layer_size, input_layer_size + 1);
Delta3 = zeros(num_labels, hidden_layer_size + 1);

for t = 1:m,
% Note that we have put bias unit in X above
	a1 = transpose(X(t, :));
	% Feedforward
	z2 = Theta1 * a1;
	a2 = [1; sigmoid(z2)];
	z3 = Theta2 * a2;
	a3 = sigmoid(z3);
% backpropagation
	temp_y = zeros(num_labels, 1);
	temp_y(y(t)) = 1;
	delta3 = a3 - temp_y;
	delta2 = (transpose(Theta2) * delta3)(2:end) .* sigmoidGradient(z2);
	Delta3 = Delta3 + delta3 * transpose(a2);
	Delta2 = Delta2 + delta2 * transpose(a1);
end

Theta1_grad = Delta2 ./ m;
Theta2_grad = Delta3 ./ m;
{% endhighlight %}

Be clear that there exists only bias for `a` and no bias for `z`. And layer `l` doesn't contribute to the `bias` in layer `i+1`. So note that

```
z2 = Theta1 * a1;
z2 = [1; z2];
a2 = sigmoid(z2);
```

is **WRONG**. You should calculate as

```
z2 = Theta1 * a1;
a2 = [1; sigmoid(z2)];
```

Finally, pay attention to the size of `delta` and `Delta`.

##### BPNN (Vectorization)

See

> https://www.coursera.org/learn/machine-learning/programming/AiHgN/neural-network-learning/discussions/threads/QFnrpQckEeWv5yIAC00Eog  
> https://www.coursera.org/learn/machine-learning/discussions/all/threads/a8Kce_WxEeS16yIACyoj1Q  
> https://www.coursera.org/learn/machine-learning/resources/Uuxg6  

{% highlight matlab %}
X = [ones(m, 1) X];
A1 = transpose(X);
Z2 = Theta1 * A1;
A2 = sigmoid(Z2);
A2 = [ones(1, size(A2)(2)); A2];
Z3 = Theta2 * A2;
A3 = transpose(sigmoid(Z3)); % A3 is 5000 * 10
vtemp_y = eye(num_labels)(y, :); % trick!
vdelta3 = A3 - vtemp_y;
vdelta2 = (vdelta3 * Theta2)(:, 2:end) .* sigmoidGradient(transpose(Z2));
vDelta3 = transpose(vdelta3) * transpose(A2);
vDelta2 = transpose(vdelta2) * transpose(A1);

J = sum(sum(-vtemp_y .* log(A3) - (1 - vtemp_y) .* log(1 - A3)));
J = J / m;
J = J + (lambda / (2 * m)) * (sum(sum(Theta1(:, 2:end) .^ 2)) ...
	+ sum(sum(Theta2(:, 2:end) .^ 2)));
{% endhighlight %}

**There are some tricks.**

Expand `y` to `m * K`:

```
vtemp_y = eye(num_labels)(y, :);
```

This is an index trick about which I do not know the details.

Another trick which can do the same thing:

```
vtemp_y = [1:num_labels] == y;
```

You can use this trick since version 3.6.0 of Octave. That is `Broadcasting` feature. When `==` operating is going, `[1:num_labels]` vector will be currently expanded to `m * num_labels` and `y` will be currently expanded to `m * num_labels`.

See [GNU Octave Doc](http://www.gnu.org/software/octave/doc/interpreter/Broadcasting.html) for more details.

Use `trace` or `sum(sum())` to calculate the sum of matrix:

```
J = sum(sum(-vtemp_y .* log(A3) - (1 - vtemp_y) .* log(1 - A3)));
```

The vectorization method is much faster than `for` iteration!

Thank you, mentor Tom!

##### Bonus: Classify Your Own Images of Digits

See

> https://www.coursera.org/learn/machine-learning/resources/EcbzQ

We will use image below:

![]({{ site.url }}/resources/pictures/ml-four.jpg)

Our classifier in `ex4` needs 20*20 pixels black and white images converted in a row vector of 400 real numbers.

Each pixel is represented by a real number between -1.0 to 1.0, meaning -1.0 equal black and 1.0 equal white.

Steps:

- Load images(.jpg)
- Convert to black&white
- Cropping to square image
- Scaling to 20*20 pixels
- Black&white to gray&white
- Rotation of image

Then you have a sample like that in the training data set. And use the classifier to predict the converted image.

Follow in code:

{% highlight matlab %}
function vectorImage = imageTo20x20Gray(fileName, cropPercentage=0, rotStep=0)
% Read as RGB image
Image3DmatrixRGB = imread(fileName);
% Convert to NTSC image (YIQ)
Image3DmatrixYIQ = rgb2ntsc(Image3DmatrixRGB);
% Convert to grays keeping only luminance (Y) and discard chrominance (IQ)
Image2DmatrixBW  = Image3DmatrixYIQ(:,:,1);
% Get the size of your image
oldSize = size(Image2DmatrixBW);
% Obtain crop size toward centered square (cropDelta)
cropDelta = floor((oldSize - min(oldSize)) .* (cropPercentage/100));
% Compute the desired final pixel size for the original image
finalSize = oldSize - cropDelta;
% Compute each dimension origin for croping
cropOrigin = floor(cropDelta / 2) + 1;
% Compute each dimension copying size
copySize = cropOrigin + finalSize - 1;
% Copy just the desired cropped image from the original B&W image
croppedImage = Image2DmatrixBW( ...
	cropOrigin(1):copySize(1), cropOrigin(2):copySize(2));
% Resolution scale factors: [rows cols]
scale = [20 20] ./ finalSize;
% Compute back the new image size (extra step to keep code general)
newSize = max(floor(scale .* finalSize),1); 
% Compute a re-sampled set of indices:
rowIndex = min(round(((1:newSize(1))-0.5)./scale(1)+0.5), finalSize(1));
colIndex = min(round(((1:newSize(2))-0.5)./scale(2)+0.5), finalSize(2));
% Copy just the indexed values from old image to get new image
newImage = croppedImage(rowIndex,colIndex,:);
% Rotate if needed: -1 is CCW, 0 is no rotate, 1 is CW
newAlignedImage = rot90(newImage, rotStep);
% Invert black and white
invertedImage = - newAlignedImage;
% Find min and max grays values in the image
maxValue = max(invertedImage(:));
minValue = min(invertedImage(:));
% Compute the value range of actual grays
delta = maxValue - minValue;
% Normalize grays between 0 and 1
normImage = (invertedImage - minValue) / delta;
% Add contrast. Multiplication factor is contrast control.
contrastedImage = sigmoid((normImage -0.5) * 5);
% Show image as seen by the classifier
imshow(contrastedImage, [-1, 1] );
% Output the matrix as a unrolled vector
vectorImage = reshape(contrastedImage, 1, newSize(1)*newSize(2));
end
{% endhighlight %}

Finally, you can see the result:

![]({{ site.url }}/resources/pictures/ml-graywhite-four.jpg)

#### Week 6

#### Week 7

#### Week 8

#### Week 9

#### Week 10

#### Week 11

### Summary



### Reference

- [Coursera: Machine Learning](https://www.coursera.org/learn/machine-learning/)